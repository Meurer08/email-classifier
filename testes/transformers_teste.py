from transformers import pipeline
import torch

# === CLASSIFICAﾃﾃグ ===
classifier = pipeline(
    "zero-shot-classification",
    model="facebook/bart-large-mnli",
    device=0 if torch.cuda.is_available() else -1
)

# === SELEﾃﾃグ DO MODELO DE GERAﾃﾃグ ===
# Vocﾃｪ pode alternar aqui 燥
model_name = "Qwen/Qwen2.5-1.5B-Instruct"
#model_name = "brazilian-devs/gpt-neo-pt-1.3B-instruct"

generator = pipeline(
    "text-generation",
    model=model_name,
    device=0 if torch.cuda.is_available() else -1
)

CANDIDATOS_CLASSIFICACAO = {
    "Produtivo": "Urgencia, Requer aﾃｧﾃ｣o imediata, trabalho a ser feito ou solicitaﾃｧﾃ｣o",
    "Improdutivo": "Mensagem de cortesia, agradecimento ou felicitaﾃｧﾃ｣o"
}

texto_email = """Assunto: 脂 Boas Festas e Agradecimento pela Parceria em 2025!

Prezada Equipe,

Em nome de toda a nossa divisﾃ｣o, gostarﾃｭamos de expressar nossa profunda gratidﾃ｣o pela parceria de sucesso que tivemos ao longo deste ano.

O trabalho em conjunto no projeto de otimizaﾃｧﾃ｣o de custos foi fundamental, e agradecemos imensamente a dedicaﾃｧﾃ｣o de todos.

Desejamos a vocﾃｪs e suas famﾃｭlias um Natal muito feliz e um excelente comeﾃｧo de 2026!

Atenciosamente,

Joﾃ｣o Silva Gerente de Relacionamento
"""

# === CLASSIFICAﾃﾃグ ===
candidatos = list(CANDIDATOS_CLASSIFICACAO.values())
resultado_classificacao = classifier(texto_email, candidatos, multi_label=False)
print(resultado_classificacao)

categoria = resultado_classificacao['labels'][0]
mapeamento_reverso = {v: k for k, v in CANDIDATOS_CLASSIFICACAO.items()}
categoria_final = mapeamento_reverso.get(categoria, 'ERRO')
print("Categoria:", categoria_final)

# === PROMPT ===
if categoria_final == "Produtivo":
    prompt = (
        "Vocﾃｪ ﾃｩ um assistente corporativo responsﾃ｡vel por responder e-mails profissionais.\n"
        "Responda de forma breve, formal e educada, informando que a solicitaﾃｧﾃ｣o estﾃ｡ sendo analisada e que o retorno serﾃ｡ enviado em breve.\n"
        "Evite se desculpar ou inventar informaﾃｧﾃｵes novas.\n"
        "Nﾃ｣o repita o conteﾃｺdo do e-mail original.\n"
        "Apenas escreva o corpo da resposta, sem assinatura nem tﾃｭtulo.\n\n"
        f"E-mail recebido:\n{texto_email}\n\n"
        "Resposta:\nPrezado(a), "
    )
else:
    prompt = (
        "Vocﾃｪ ﾃｩ um assistente cordial de e-mails corporativos.\n"
        "Escreva uma resposta curta e simpﾃ｡tica de agradecimento ﾃ mensagem recebida.\n"
        "Apenas escreva o corpo da resposta, sem assinatura nem tﾃｭtulo.\n\n"
        "Nﾃ｣o repita o e-mail, apenas agradeﾃｧa de forma natural.\n\n"
        f"E-mail recebido:\n{texto_email}\n\n"
        "Resposta:\nPrezado(a), "
    )

print("\nGerando Resposta...\n")

# === GERAﾃﾃグ ===
resposta_gerada = generator(
    prompt,
    do_sample=True,
    temperature=0.3,
    top_p=0.5,
    top_k=40,
    max_new_tokens=120,
    repetition_penalty=1.2,
    pad_token_id=generator.tokenizer.eos_token_id
)[0]['generated_text']

resposta_final = resposta_gerada.split("Resposta:")[-1].strip()
print("Resposta final:\n")
print(resposta_final)
