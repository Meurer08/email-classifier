from transformers import pipeline
import torch

# === CLASSIFICA√á√ÉO ===
classifier = pipeline(
    "zero-shot-classification",
    model="facebook/bart-large-mnli",
    device=0 if torch.cuda.is_available() else -1
)

# === SELE√á√ÉO DO MODELO DE GERA√á√ÉO ===
# Voc√™ pode alternar aqui üëá
model_name = "Qwen/Qwen2.5-1.5B-Instruct"
#model_name = "brazilian-devs/gpt-neo-pt-1.3B-instruct"

generator = pipeline(
    "text-generation",
    model=model_name,
    device=0 if torch.cuda.is_available() else -1
)

CANDIDATOS_CLASSIFICACAO = {
    "Produtivo": "Urgencia, Requer a√ß√£o imediata, trabalho a ser feito ou solicita√ß√£o",
    "Improdutivo": "Mensagem de cortesia, agradecimento ou felicita√ß√£o"
}

texto_email = """Assunto: üéâ Boas Festas e Agradecimento pela Parceria em 2025!

Prezada Equipe,

Em nome de toda a nossa divis√£o, gostar√≠amos de expressar nossa profunda gratid√£o pela parceria de sucesso que tivemos ao longo deste ano.

O trabalho em conjunto no projeto de otimiza√ß√£o de custos foi fundamental, e agradecemos imensamente a dedica√ß√£o de todos.

Desejamos a voc√™s e suas fam√≠lias um Natal muito feliz e um excelente come√ßo de 2026!

Atenciosamente,

Jo√£o Silva Gerente de Relacionamento
"""

candidatos = list(CANDIDATOS_CLASSIFICACAO.values())
resultado_classificacao = classifier(texto_email, candidatos, multi_label=False)
print(resultado_classificacao)

categoria = resultado_classificacao['labels'][0]
mapeamento_reverso = {v: k for k, v in CANDIDATOS_CLASSIFICACAO.items()}
categoria_final = mapeamento_reverso.get(categoria, 'ERRO')
print("Categoria:", categoria_final)


if categoria_final == "Produtivo":
    prompt = (
        "Voc√™ √© um assistente corporativo respons√°vel por responder e-mails profissionais.\n"
        "Responda de forma breve, formal e educada, informando que a solicita√ß√£o est√° sendo analisada e que o retorno ser√° enviado em breve.\n"
        "Evite se desculpar ou inventar informa√ß√µes novas.\n"
        "N√£o repita o conte√∫do do e-mail original.\n"
        "Apenas escreva o corpo da resposta.\n" 
        "sem assinatura nem t√≠tulo.\n\n"
        "Apenas a resposta em texto simples.\n\n"
        f"E-mail recebido:\n{texto_email}\n\n"
        "Resposta:\nPrezado(a), "
    )
else:
    prompt = (
        "Voc√™ √© um assistente cordial de e-mails corporativos.\n"
        "Escreva uma resposta curta e simp√°tica de agradecimento √† mensagem recebida.\n"
        "Apenas escreva o corpo da resposta.\n" 
        "sem assinatura nem t√≠tulo.\n\n"
        "Apenas a resposta.\n\n"
        "N√£o repita o e-mail, apenas agrade√ßa de forma natural.\n\n"
        f"E-mail recebido:\n{texto_email}\n\n"
        "Resposta:\nPrezado(a), "
    )

print("\nGerando Resposta...\n")


resposta_gerada = generator(
    prompt,
    do_sample=True,
    temperature=0.3,
    top_p=0.5,
    top_k=40,
    max_new_tokens=120,
    repetition_penalty=1.2,
    pad_token_id=generator.tokenizer.eos_token_id
)[0]['generated_text']

resposta_final = resposta_gerada.split("Resposta:")[-1].strip()
print("Resposta final:\n")
print(resposta_final)
